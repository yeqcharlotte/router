# vLLM Router CI/CD Pipeline
# This pipeline runs automated checks, builds, and tests for the vLLM Router project

env:
  # Disable incremental compilation for consistent CI builds
  CARGO_INCREMENTAL: "0"
  # Enable full Rust backtraces for debugging
  RUST_BACKTRACE: "1"

steps:
  # ============================================================================
  # Fast Checks - Run in parallel for quick feedback
  # ============================================================================
  - group: ":mag: Fast Checks"
    key: "fast-checks"
    steps:
      - label: ":rust: Rust Format Check"
        plugins:
          - docker#v5.11.0:
              image: "rustlang/rust:nightly-bullseye"
              workdir: /workdir
              volumes:
                - ".:/workdir"
              environment:
                - "CARGO_INCREMENTAL=0"
                - "RUST_BACKTRACE=1"
              command:
                - bash
                - -c
                - |
                  rustup component add rustfmt
                  cargo fmt --check
        agents:
          queue: "cpu_queue_premerge"

      - label: ":rust: Clippy"
        plugins:
          - docker#v5.11.0:
              image: "rustlang/rust:nightly-bullseye"
              workdir: /workdir
              volumes:
                - ".:/workdir"
              environment:
                - "CARGO_INCREMENTAL=0"
                - "RUST_BACKTRACE=1"
              command:
                - bash
                - -c
                - |
                  apt-get update && apt-get install -y pkg-config libssl-dev protobuf-compiler
                  rustup component add clippy
                  cargo clippy --all-targets --all-features -- -D warnings
        agents:
          queue: "cpu_queue_premerge"

      - label: ":python: Python Format Check"
        command: |
          pip install black ruff
          python -m black --check py_src/ py_test/
          python -m ruff check py_src/ py_test/
        agents:
          queue: "cpu_queue_premerge"

  # Wait for fast checks to pass before building
  - wait: ~
    continue_on_failure: false

  # ============================================================================
  # Build - Create release artifacts
  # ============================================================================
  - group: ":hammer: Build"
    key: "build"
    steps:
      - label: ":rust: Build Rust (Release)"
        plugins:
          - docker#v5.11.0:
              image: "rustlang/rust:nightly-bullseye"
              workdir: /workdir
              volumes:
                - ".:/workdir"
              environment:
                - "CARGO_INCREMENTAL=0"
                - "RUST_BACKTRACE=1"
              command:
                - bash
                - -c
                - |
                  apt-get update && apt-get install -y pkg-config libssl-dev protobuf-compiler
                  cargo build --release
        artifact_paths:
          - "target/release/vllm-router"
        agents:
          queue: "cpu_queue_premerge"

      - label: ":python: Build Python Wheel"
        plugins:
          - docker#v5.11.0:
              image: "rustlang/rust:nightly-bullseye"
              workdir: /workdir
              volumes:
                - ".:/workdir"
              environment:
                - "CARGO_INCREMENTAL=0"
                - "RUST_BACKTRACE=1"
              command:
                - bash
                - -c
                - |
                  apt-get update && apt-get install -y pkg-config libssl-dev protobuf-compiler python3 python3-pip
                  pip3 install -U pip setuptools wheel setuptools-rust build
                  python3 -m build
        artifact_paths:
          - "dist/*.whl"
          - "dist/*.tar.gz"
        agents:
          queue: "cpu_queue_premerge"

  # Wait for builds to complete before testing
  - wait: ~
    continue_on_failure: false

  # ============================================================================
  # Tests - Run comprehensive test suite
  # ============================================================================
  - group: ":test_tube: Tests"
    key: "tests"
    steps:
      - label: ":rust: Rust Unit Tests"
        plugins:
          - docker#v5.11.0:
              image: "rustlang/rust:nightly-bullseye"
              workdir: /workdir
              volumes:
                - ".:/workdir"
              environment:
                - "CARGO_INCREMENTAL=0"
                - "RUST_BACKTRACE=1"
              command:
                - bash
                - -c
                - |
                  apt-get update && apt-get install -y pkg-config libssl-dev protobuf-compiler
                  cargo test --lib --bins
        agents:
          queue: "cpu_queue_premerge"

      - label: ":rust: Rust Integration Tests"
        plugins:
          - docker#v5.11.0:
              image: "rustlang/rust:nightly-bullseye"
              workdir: /workdir
              volumes:
                - ".:/workdir"
              environment:
                - "CARGO_INCREMENTAL=0"
                - "RUST_BACKTRACE=1"
              command:
                - bash
                - -c
                - |
                  apt-get update && apt-get install -y pkg-config libssl-dev protobuf-compiler
                  cargo test --test '*'
        agents:
          queue: "cpu_queue_premerge"

      - label: ":python: Python Tests"
        plugins:
          - docker#v5.11.0:
              image: "rustlang/rust:nightly-bullseye"
              workdir: /workdir
              volumes:
                - ".:/workdir"
              environment:
                - "CARGO_INCREMENTAL=0"
                - "RUST_BACKTRACE=1"
              command:
                - bash
                - -c
                - |
                  apt-get update && apt-get install -y pkg-config libssl-dev protobuf-compiler python3 python3-pip
                  pip3 install -U pip setuptools wheel setuptools-rust
                  pip3 install -e .[dev]
                  pip3 install pytest pytest-cov pytest-asyncio
                  pytest py_test/ -v --ignore=py_test/e2e --cov=vllm_router --cov-report=xml --cov-report=term
        artifact_paths:
          - "coverage.xml"
        agents:
          queue: "cpu_queue_premerge"

  # ============================================================================
  # P/D Disaggregation Integration Test - Run on GPU queue
  # ============================================================================
  - label: ":satellite: P/D Disaggregation Test (4 GPUs)"
    key: "pd-disagg-test"
    timeout_in_minutes: 60
    retry:
      automatic:
        - exit_status: "*"
          limit: 2
      manual:
        allowed: true
        reason: "GPU tests can be flaky - retry if needed"
    plugins:
      - docker#v5.11.0:
          image: "nvidia/cuda:12.9.1-devel-ubuntu22.04"
          workdir: /workdir
          volumes:
            - ".:/workdir"
            - "/root/.cache/huggingface:/root/.cache/huggingface"
          runtime: nvidia
          gpus: all
          shm-size: "16g"
          environment:
            - "HF_TOKEN"
            - "VLLM_USE_V1=1"
            - "VLLM_LOGGING_LEVEL=INFO"
            - "UCX_TLS=all"
            - "UCX_NET_DEVICES=all"
          propagate-environment: true
          command:
            - bash
            - -c
            - |
              set -euo pipefail

              # Verify HF_TOKEN is set (required for gated models like Llama)
              if [ -z "$${HF_TOKEN:-}" ]; then
                echo "ERROR: HF_TOKEN is not set. This is required for gated models."
                echo "Please configure HF_TOKEN as a Buildkite Secret in Organization Settings."
                exit 1
              fi
              echo "HF_TOKEN is configured."

              # Install system dependencies
              apt-get update && apt-get install -y \
                curl \
                python3 \
                python3-pip \
                pkg-config \
                libssl-dev \
                protobuf-compiler \
                git

              # Install uv for fast Python package management
              curl -LsSf https://astral.sh/uv/install.sh | sh
              source /root/.local/bin/env

              # Create Python virtual environment (as recommended by vLLM)
              uv venv --python 3.12 --seed
              source .venv/bin/activate

              # Install vLLM with CUDA 12.8 support
              uv pip install vllm --torch-backend=auto

              # Install NIXL library for P/D disaggregation
              uv pip install nixl

              # Install test dependencies
              uv pip install requests pytest openai

              # Install LM Evaluation Harness with API extras for accuracy testing
              uv pip install 'lm-eval[api]>=0.4.0'

              # Install Rust for building the router
              curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
              source /root/.cargo/env

              # Build the router
              cargo build --release
              export PATH="/workdir/target/release:$$PATH"

              # Run P/D disaggregation test
              cd py_test/e2e/pd_disagg_vllm
              bash ./run_accuracy_test.sh
    agents:
      queue: "gpu_4_queue"
    depends_on: "build"
    artifact_paths:
      - "/tmp/router.log"

  # ============================================================================
  # Docker Build - Parallel with tests
  # ============================================================================
  - label: ":docker: Build Docker Image"
    command: |
      docker build -f Dockerfile.router -t vllm-router:${BUILDKITE_COMMIT} .
      docker tag vllm-router:${BUILDKITE_COMMIT} vllm-router:latest
    agents:
      queue: "cpu_queue_premerge"
    depends_on: "build"
