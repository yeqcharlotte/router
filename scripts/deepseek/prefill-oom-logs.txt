DEBUG 10-17 09:23:36 [plugins/__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 10-17 09:23:36 [platforms/__init__.py:34] Checking if TPU platform is available.
DEBUG 10-17 09:23:36 [platforms/__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 10-17 09:23:36 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:36 [platforms/__init__.py:78] Confirmed CUDA platform is available.
DEBUG 10-17 09:23:36 [platforms/__init__.py:106] Checking if ROCm platform is available.
DEBUG 10-17 09:23:36 [platforms/__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 10-17 09:23:36 [platforms/__init__.py:127] Checking if XPU platform is available.
DEBUG 10-17 09:23:36 [platforms/__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 10-17 09:23:36 [platforms/__init__.py:153] Checking if CPU platform is available.
DEBUG 10-17 09:23:36 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:36 [platforms/__init__.py:78] Confirmed CUDA platform is available.
INFO 10-17 09:23:36 [platforms/__init__.py:216] Automatically detected platform cuda.
DEBUG 10-17 09:23:42 [entrypoints/utils.py:163] Setting VLLM_WORKER_MULTIPROC_METHOD to 'spawn'
DEBUG 10-17 09:23:42 [plugins/__init__.py:36] Available plugins for group vllm.general_plugins:
DEBUG 10-17 09:23:42 [plugins/__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
DEBUG 10-17 09:23:42 [plugins/__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[1;36m(APIServer pid=1)[0;0m INFO 10-17 09:23:42 [entrypoints/openai/api_server.py:1839] vLLM API server version 0.11.0
[1;36m(APIServer pid=1)[0;0m INFO 10-17 09:23:42 [entrypoints/utils.py:233] non-default args: {'model_tag': 'deepseek-ai/DeepSeek-V3-0324', 'host': '0.0.0.0', 'port': 20003, 'model': 'deepseek-ai/DeepSeek-V3-0324', 'trust_remote_code': True, 'enforce_eager': True, 'data_parallel_size': 8, 'enable_expert_parallel': True, 'enable_prefix_caching': True, 'kv_transfer_config': KVTransferConfig(kv_connector='NixlConnector', engine_id='2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80', kv_buffer_device='cuda', kv_buffer_size=1000000000.0, kv_role='kv_both', kv_rank=None, kv_parallel_size=1, kv_ip='127.0.0.1', kv_port=14579, kv_connector_extra_config={'backends': ['UCX', 'GDS']}, kv_connector_module_path=None), 'disable_log_stats': True}
[1;36m(APIServer pid=1)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[1;36m(APIServer pid=1)[0;0m INFO 10-17 09:23:43 [transformers_utils/config.py:388] Replacing legacy 'type' key with 'rope_type'
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:23:43 [model_executor/models/registry.py:450] Cached model info file for class vllm.model_executor.models.deepseek_v2.DeepseekV3ForCausalLM not found
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:23:43 [model_executor/models/registry.py:503] Cache model info for class vllm.model_executor.models.deepseek_v2.DeepseekV3ForCausalLM miss. Loading model instead.
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:23:48 [model_executor/models/registry.py:511] Loaded model info for class vllm.model_executor.models.deepseek_v2.DeepseekV3ForCausalLM
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:23:48 [logging_utils/log_time.py:27] Registry inspect model class: Elapsed time 5.6129089 secs
[1;36m(APIServer pid=1)[0;0m INFO 10-17 09:23:49 [config/model.py:547] Resolved architecture: DeepseekV3ForCausalLM
[1;36m(APIServer pid=1)[0;0m `torch_dtype` is deprecated! Use `dtype` instead!
[1;36m(APIServer pid=1)[0;0m INFO 10-17 09:23:49 [config/model.py:1510] Using max model len 163840
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:23:49 [_ipex_ops.py:16] Import error msg: No module named 'intel_extension_for_pytorch'
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:23:49 [engine/arg_utils.py:1672] Setting max_num_batched_tokens to 8192 for OPENAI_API_SERVER usage context.
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:23:49 [engine/arg_utils.py:1681] Setting max_num_seqs to 1024 for OPENAI_API_SERVER usage context.
[1;36m(APIServer pid=1)[0;0m INFO 10-17 09:23:49 [config/scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(APIServer pid=1)[0;0m INFO 10-17 09:23:49 [config/__init__.py:381] Cudagraph is disabled under eager mode
[1;36m(APIServer pid=1)[0;0m INFO 10-17 09:23:49 [platforms/cuda.py:166] Forcing kv cache block size to 64 for FlashMLA backend.
[1;36m(APIServer pid=1)[0;0m INFO 10-17 09:23:50 [transformers_utils/config.py:388] Replacing legacy 'type' key with 'rope_type'
[1;36m(APIServer pid=1)[0;0m INFO 10-17 09:23:50 [v1/engine/utils.py:651] Started DP Coordinator process (PID: 269)
DEBUG 10-17 09:23:53 [plugins/__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 10-17 09:23:53 [platforms/__init__.py:34] Checking if TPU platform is available.
DEBUG 10-17 09:23:53 [plugins/__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 10-17 09:23:53 [platforms/__init__.py:34] Checking if TPU platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 10-17 09:23:53 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 10-17 09:23:53 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:78] Confirmed CUDA platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:78] Confirmed CUDA platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:106] Checking if ROCm platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 10-17 09:23:53 [platforms/__init__.py:127] Checking if XPU platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 10-17 09:23:53 [platforms/__init__.py:153] Checking if CPU platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:106] Checking if ROCm platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 10-17 09:23:53 [platforms/__init__.py:127] Checking if XPU platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 10-17 09:23:53 [platforms/__init__.py:153] Checking if CPU platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:53 [plugins/__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 10-17 09:23:53 [platforms/__init__.py:34] Checking if TPU platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 10-17 09:23:53 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:53 [plugins/__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 10-17 09:23:53 [platforms/__init__.py:34] Checking if TPU platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 10-17 09:23:53 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:53 [plugins/__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 10-17 09:23:53 [platforms/__init__.py:34] Checking if TPU platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 10-17 09:23:53 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:78] Confirmed CUDA platform is available.
DEBUG 10-17 09:23:53 [platforms/__init__.py:78] Confirmed CUDA platform is available.
INFO 10-17 09:23:53 [platforms/__init__.py:216] Automatically detected platform cuda.
INFO 10-17 09:23:54 [platforms/__init__.py:216] Automatically detected platform cuda.
DEBUG 10-17 09:23:54 [platforms/__init__.py:78] Confirmed CUDA platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:106] Checking if ROCm platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 10-17 09:23:54 [platforms/__init__.py:127] Checking if XPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 10-17 09:23:54 [platforms/__init__.py:153] Checking if CPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:78] Confirmed CUDA platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:106] Checking if ROCm platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 10-17 09:23:54 [platforms/__init__.py:127] Checking if XPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 10-17 09:23:54 [platforms/__init__.py:153] Checking if CPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:54 [plugins/__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 10-17 09:23:54 [platforms/__init__.py:34] Checking if TPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 10-17 09:23:54 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:54 [plugins/__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 10-17 09:23:54 [platforms/__init__.py:34] Checking if TPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 10-17 09:23:54 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:78] Confirmed CUDA platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:106] Checking if ROCm platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 10-17 09:23:54 [platforms/__init__.py:127] Checking if XPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 10-17 09:23:54 [platforms/__init__.py:153] Checking if CPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:54 [plugins/__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 10-17 09:23:54 [platforms/__init__.py:34] Checking if TPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 10-17 09:23:54 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:78] Confirmed CUDA platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:78] Confirmed CUDA platform is available.
INFO 10-17 09:23:54 [platforms/__init__.py:216] Automatically detected platform cuda.
DEBUG 10-17 09:23:54 [platforms/__init__.py:78] Confirmed CUDA platform is available.
INFO 10-17 09:23:54 [platforms/__init__.py:216] Automatically detected platform cuda.
DEBUG 10-17 09:23:54 [platforms/__init__.py:106] Checking if ROCm platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 10-17 09:23:54 [platforms/__init__.py:127] Checking if XPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 10-17 09:23:54 [platforms/__init__.py:153] Checking if CPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:54 [plugins/__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 10-17 09:23:54 [platforms/__init__.py:34] Checking if TPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 10-17 09:23:54 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:78] Confirmed CUDA platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:78] Confirmed CUDA platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:106] Checking if ROCm platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 10-17 09:23:54 [platforms/__init__.py:127] Checking if XPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 10-17 09:23:54 [platforms/__init__.py:153] Checking if CPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:58] Checking if CUDA platform is available.
INFO 10-17 09:23:54 [platforms/__init__.py:216] Automatically detected platform cuda.
DEBUG 10-17 09:23:54 [platforms/__init__.py:78] Confirmed CUDA platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:106] Checking if ROCm platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 10-17 09:23:54 [platforms/__init__.py:127] Checking if XPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 10-17 09:23:54 [platforms/__init__.py:153] Checking if CPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:78] Confirmed CUDA platform is available.
INFO 10-17 09:23:54 [platforms/__init__.py:216] Automatically detected platform cuda.
DEBUG 10-17 09:23:54 [platforms/__init__.py:78] Confirmed CUDA platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:78] Confirmed CUDA platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:106] Checking if ROCm platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 10-17 09:23:54 [platforms/__init__.py:127] Checking if XPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 10-17 09:23:54 [platforms/__init__.py:153] Checking if CPU platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-17 09:23:54 [platforms/__init__.py:78] Confirmed CUDA platform is available.
INFO 10-17 09:23:54 [platforms/__init__.py:216] Automatically detected platform cuda.
INFO 10-17 09:23:55 [platforms/__init__.py:216] Automatically detected platform cuda.
DEBUG 10-17 09:23:55 [platforms/__init__.py:78] Confirmed CUDA platform is available.
INFO 10-17 09:23:55 [platforms/__init__.py:216] Automatically detected platform cuda.
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:23:58 [v1/engine/core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:23:58 [v1/engine/core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:23:58 [v1/engine/core.py:652] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/fe72b14f-9184-4002-af6f-dbc1252296cd'], outputs=['ipc:///tmp/565eed3a-edcd-4f5d-8738-03d774756823'], coordinator_input='ipc:///tmp/b43fc170-d5ee-4383-a3db-7a1a392b7edf', coordinator_output='ipc:///tmp/0b1e3afb-dfb8-4b9f-9ec9-902f5bc5e5e4', frontend_stats_publish_address='ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1'), parallel_config={'data_parallel_master_ip': '127.0.0.1', 'data_parallel_master_port': 57501, '_data_parallel_master_port_list': [52929, 46215, 42763, 34647], 'data_parallel_size': 8})
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:23:58 [v1/engine/core.py:487] Has DP Coordinator: True, stats publish address: ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:23:58 [v1/engine/core.py:985] Setting kv_transfer_config.engine_id to 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp4
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:23:58 [v1/engine/utils.py:859] HELLO from local core engine process 4.
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:23:58 [v1/engine/utils.py:859] HELLO from local core engine process 0.
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:23:58 [v1/engine/core.py:652] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/fe72b14f-9184-4002-af6f-dbc1252296cd'], outputs=['ipc:///tmp/565eed3a-edcd-4f5d-8738-03d774756823'], coordinator_input='ipc:///tmp/b43fc170-d5ee-4383-a3db-7a1a392b7edf', coordinator_output='ipc:///tmp/0b1e3afb-dfb8-4b9f-9ec9-902f5bc5e5e4', frontend_stats_publish_address='ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1'), parallel_config={'data_parallel_master_ip': '127.0.0.1', 'data_parallel_master_port': 57501, '_data_parallel_master_port_list': [52929, 46215, 42763, 34647], 'data_parallel_size': 8})
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:23:58 [v1/engine/core.py:487] Has DP Coordinator: True, stats publish address: ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:23:58 [v1/engine/core.py:985] Setting kv_transfer_config.engine_id to 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp0
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:23:58 [v1/engine/core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:23:58 [v1/engine/core.py:652] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/fe72b14f-9184-4002-af6f-dbc1252296cd'], outputs=['ipc:///tmp/565eed3a-edcd-4f5d-8738-03d774756823'], coordinator_input='ipc:///tmp/b43fc170-d5ee-4383-a3db-7a1a392b7edf', coordinator_output='ipc:///tmp/0b1e3afb-dfb8-4b9f-9ec9-902f5bc5e5e4', frontend_stats_publish_address='ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1'), parallel_config={'data_parallel_master_ip': '127.0.0.1', 'data_parallel_master_port': 57501, '_data_parallel_master_port_list': [52929, 46215, 42763, 34647], 'data_parallel_size': 8})
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:23:58 [v1/engine/core.py:487] Has DP Coordinator: True, stats publish address: ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:23:58 [v1/engine/utils.py:859] HELLO from local core engine process 2.
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:23:58 [v1/engine/core.py:985] Setting kv_transfer_config.engine_id to 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp2
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:23:59 [v1/engine/core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:23:59 [v1/engine/core.py:652] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/fe72b14f-9184-4002-af6f-dbc1252296cd'], outputs=['ipc:///tmp/565eed3a-edcd-4f5d-8738-03d774756823'], coordinator_input='ipc:///tmp/b43fc170-d5ee-4383-a3db-7a1a392b7edf', coordinator_output='ipc:///tmp/0b1e3afb-dfb8-4b9f-9ec9-902f5bc5e5e4', frontend_stats_publish_address='ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1'), parallel_config={'data_parallel_master_ip': '127.0.0.1', 'data_parallel_master_port': 57501, '_data_parallel_master_port_list': [52929, 46215, 42763, 34647], 'data_parallel_size': 8})
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:23:59 [v1/engine/core.py:487] Has DP Coordinator: True, stats publish address: ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:23:59 [v1/engine/utils.py:859] HELLO from local core engine process 1.
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:23:59 [v1/engine/core.py:985] Setting kv_transfer_config.engine_id to 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp1
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:23:59 [v1/engine/core.py:644] Waiting for init message from front-end.
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:23:59 [v1/engine/utils.py:859] HELLO from local core engine process 6.
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:23:59 [v1/engine/core.py:652] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/fe72b14f-9184-4002-af6f-dbc1252296cd'], outputs=['ipc:///tmp/565eed3a-edcd-4f5d-8738-03d774756823'], coordinator_input='ipc:///tmp/b43fc170-d5ee-4383-a3db-7a1a392b7edf', coordinator_output='ipc:///tmp/0b1e3afb-dfb8-4b9f-9ec9-902f5bc5e5e4', frontend_stats_publish_address='ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1'), parallel_config={'data_parallel_master_ip': '127.0.0.1', 'data_parallel_master_port': 57501, '_data_parallel_master_port_list': [52929, 46215, 42763, 34647], 'data_parallel_size': 8})
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:23:59 [v1/engine/core.py:487] Has DP Coordinator: True, stats publish address: ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:23:59 [v1/engine/core.py:985] Setting kv_transfer_config.engine_id to 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp6
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:23:59 [v1/engine/core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:23:59 [v1/engine/core.py:652] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/fe72b14f-9184-4002-af6f-dbc1252296cd'], outputs=['ipc:///tmp/565eed3a-edcd-4f5d-8738-03d774756823'], coordinator_input='ipc:///tmp/b43fc170-d5ee-4383-a3db-7a1a392b7edf', coordinator_output='ipc:///tmp/0b1e3afb-dfb8-4b9f-9ec9-902f5bc5e5e4', frontend_stats_publish_address='ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1'), parallel_config={'data_parallel_master_ip': '127.0.0.1', 'data_parallel_master_port': 57501, '_data_parallel_master_port_list': [52929, 46215, 42763, 34647], 'data_parallel_size': 8})
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:23:59 [v1/engine/utils.py:859] HELLO from local core engine process 7.
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:23:59 [v1/engine/core.py:487] Has DP Coordinator: True, stats publish address: ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:23:59 [v1/engine/core.py:985] Setting kv_transfer_config.engine_id to 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp7
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:24:00 [v1/engine/core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:24:00 [v1/engine/core.py:652] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/fe72b14f-9184-4002-af6f-dbc1252296cd'], outputs=['ipc:///tmp/565eed3a-edcd-4f5d-8738-03d774756823'], coordinator_input='ipc:///tmp/b43fc170-d5ee-4383-a3db-7a1a392b7edf', coordinator_output='ipc:///tmp/0b1e3afb-dfb8-4b9f-9ec9-902f5bc5e5e4', frontend_stats_publish_address='ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1'), parallel_config={'data_parallel_master_ip': '127.0.0.1', 'data_parallel_master_port': 57501, '_data_parallel_master_port_list': [52929, 46215, 42763, 34647], 'data_parallel_size': 8})
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:24:00 [v1/engine/core.py:487] Has DP Coordinator: True, stats publish address: ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:24:00 [v1/engine/utils.py:859] HELLO from local core engine process 5.
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:24:00 [v1/engine/core.py:985] Setting kv_transfer_config.engine_id to 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp5
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:24:00 [v1/engine/core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:24:00 [v1/engine/core.py:652] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/fe72b14f-9184-4002-af6f-dbc1252296cd'], outputs=['ipc:///tmp/565eed3a-edcd-4f5d-8738-03d774756823'], coordinator_input='ipc:///tmp/b43fc170-d5ee-4383-a3db-7a1a392b7edf', coordinator_output='ipc:///tmp/0b1e3afb-dfb8-4b9f-9ec9-902f5bc5e5e4', frontend_stats_publish_address='ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1'), parallel_config={'data_parallel_master_ip': '127.0.0.1', 'data_parallel_master_port': 57501, '_data_parallel_master_port_list': [52929, 46215, 42763, 34647], 'data_parallel_size': 8})
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:24:00 [v1/engine/utils.py:859] HELLO from local core engine process 3.
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:24:00 [v1/engine/core.py:487] Has DP Coordinator: True, stats publish address: ipc:///tmp/bbf3b9b7-faf9-4b86-a132-b24e39aab9c1
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:24:00 [v1/engine/core.py:985] Setting kv_transfer_config.engine_id to 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp3
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:36] Available plugins for group vllm.general_plugins:
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:36] Available plugins for group vllm.general_plugins:
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:36] Available plugins for group vllm.general_plugins:
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:36] Available plugins for group vllm.general_plugins:
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:24:00 [v1/engine/core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='deepseek-ai/DeepSeek-V3-0324', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-V3-0324', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=163840, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=8, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=deepseek-ai/DeepSeek-V3-0324, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:24:00 [v1/engine/core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='deepseek-ai/DeepSeek-V3-0324', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-V3-0324', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=163840, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=8, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=deepseek-ai/DeepSeek-V3-0324, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:24:00 [v1/engine/core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='deepseek-ai/DeepSeek-V3-0324', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-V3-0324', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=163840, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=8, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=deepseek-ai/DeepSeek-V3-0324, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:24:00 [v1/engine/core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='deepseek-ai/DeepSeek-V3-0324', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-V3-0324', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=163840, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=8, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=deepseek-ai/DeepSeek-V3-0324, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:36] Available plugins for group vllm.general_plugins:
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:36] Available plugins for group vllm.general_plugins:
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:36] Available plugins for group vllm.general_plugins:
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:24:00 [v1/engine/core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='deepseek-ai/DeepSeek-V3-0324', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-V3-0324', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=163840, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=8, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=deepseek-ai/DeepSeek-V3-0324, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:24:00 [v1/engine/core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='deepseek-ai/DeepSeek-V3-0324', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-V3-0324', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=163840, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=8, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=deepseek-ai/DeepSeek-V3-0324, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:24:00 [v1/engine/core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='deepseek-ai/DeepSeek-V3-0324', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-V3-0324', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=163840, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=8, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=deepseek-ai/DeepSeek-V3-0324, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:36] Available plugins for group vllm.general_plugins:
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:24:00 [plugins/__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:24:00 [v1/engine/core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='deepseek-ai/DeepSeek-V3-0324', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-V3-0324', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=163840, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=8, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=deepseek-ai/DeepSeek-V3-0324, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:24:00 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:24:00 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:24:00 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:24:00 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:24:00 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:24:00 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:24:00 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:24:00 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP6 pid=278)[0;0m W1017 09:24:02.600000 278 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1;36m(EngineCore_DP6 pid=278)[0;0m W1017 09:24:02.600000 278 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:24:02 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:24:02 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama_eagle3.LlamaModel'>: ['input_ids', 'positions', 'hidden_states']
[1;36m(EngineCore_DP4 pid=276)[0;0m W1017 09:24:03.288000 276 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1;36m(EngineCore_DP4 pid=276)[0;0m W1017 09:24:03.288000 276 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:24:03 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:24:03 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama_eagle3.LlamaModel'>: ['input_ids', 'positions', 'hidden_states']
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:24:03 [utils/__init__.py:3188] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7b8183af3080>
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:24:03 [utils/__init__.py:3188] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x78059631b950>
[1;36m(EngineCore_DP5 pid=277)[0;0m W1017 09:24:03.874000 277 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1;36m(EngineCore_DP5 pid=277)[0;0m W1017 09:24:03.874000 277 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:24:03 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:24:03 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama_eagle3.LlamaModel'>: ['input_ids', 'positions', 'hidden_states']
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:24:04 [utils/__init__.py:3188] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7408ed997110>
[1;36m(EngineCore_DP1 pid=273)[0;0m W1017 09:24:04.488000 273 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1;36m(EngineCore_DP1 pid=273)[0;0m W1017 09:24:04.488000 273 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:24:04 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:24:04 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama_eagle3.LlamaModel'>: ['input_ids', 'positions', 'hidden_states']
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:24:04 [utils/__init__.py:3188] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x72592dd5fb30>
[1;36m(EngineCore_DP0 pid=272)[0;0m W1017 09:24:05.110000 272 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1;36m(EngineCore_DP0 pid=272)[0;0m W1017 09:24:05.110000 272 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:24:05 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:24:05 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama_eagle3.LlamaModel'>: ['input_ids', 'positions', 'hidden_states']
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:24:05 [utils/__init__.py:3188] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7eb3047a6fc0>
[1;36m(EngineCore_DP2 pid=274)[0;0m W1017 09:24:05.754000 274 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1;36m(EngineCore_DP2 pid=274)[0;0m W1017 09:24:05.754000 274 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:24:05 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:24:05 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama_eagle3.LlamaModel'>: ['input_ids', 'positions', 'hidden_states']
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:24:06 [utils/__init__.py:3188] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7464aaabcc20>
[1;36m(EngineCore_DP7 pid=279)[0;0m W1017 09:24:06.507000 279 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1;36m(EngineCore_DP7 pid=279)[0;0m W1017 09:24:06.507000 279 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:24:06 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:24:06 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama_eagle3.LlamaModel'>: ['input_ids', 'positions', 'hidden_states']
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:24:06 [utils/__init__.py:3188] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fbd3e077920>
[1;36m(EngineCore_DP3 pid=275)[0;0m W1017 09:24:07.421000 275 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1;36m(EngineCore_DP3 pid=275)[0;0m W1017 09:24:07.421000 275 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:24:07 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:24:07 [compilation/decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama_eagle3.LlamaModel'>: ['input_ids', 'positions', 'hidden_states']
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:24:07 [utils/__init__.py:3188] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x70b578b0f9e0>
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:24:08 [distributed/parallel_state.py:1029] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://192.168.2.21:34969 backend=nccl
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:24:08 [distributed/parallel_state.py:1047] Adjusting world_size=8 rank=7 distributed_init_method=tcp://127.0.0.1:42763 for DP
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:24:08 [distributed/parallel_state.py:1029] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://192.168.2.21:46745 backend=nccl
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:24:08 [distributed/parallel_state.py:1047] Adjusting world_size=8 rank=6 distributed_init_method=tcp://127.0.0.1:42763 for DP
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:24:08 [distributed/parallel_state.py:1029] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://192.168.2.21:42871 backend=nccl
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:24:08 [distributed/parallel_state.py:1047] Adjusting world_size=8 rank=0 distributed_init_method=tcp://127.0.0.1:42763 for DP
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:24:08 [distributed/parallel_state.py:1029] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://192.168.2.21:41405 backend=nccl
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:24:08 [distributed/parallel_state.py:1047] Adjusting world_size=8 rank=4 distributed_init_method=tcp://127.0.0.1:42763 for DP
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:24:08 [distributed/parallel_state.py:1029] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://192.168.2.21:55393 backend=nccl
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:24:08 [distributed/parallel_state.py:1047] Adjusting world_size=8 rank=5 distributed_init_method=tcp://127.0.0.1:42763 for DP
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:24:08 [distributed/parallel_state.py:1029] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://192.168.2.21:36113 backend=nccl
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:24:08 [distributed/parallel_state.py:1047] Adjusting world_size=8 rank=1 distributed_init_method=tcp://127.0.0.1:42763 for DP
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:24:08 [distributed/parallel_state.py:1029] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://192.168.2.21:60987 backend=nccl
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:24:08 [distributed/parallel_state.py:1047] Adjusting world_size=8 rank=2 distributed_init_method=tcp://127.0.0.1:42763 for DP
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:24:08 [distributed/parallel_state.py:1029] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://192.168.2.21:42755 backend=nccl
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:24:08 [distributed/parallel_state.py:1047] Adjusting world_size=8 rank=3 distributed_init_method=tcp://127.0.0.1:42763 for DP
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:24:09 [distributed/parallel_state.py:1083] Detected 1 nodes in the distributed environment
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:24:09 [distributed/parallel_state.py:1083] Detected 1 nodes in the distributed environment
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:24:09 [distributed/parallel_state.py:1083] Detected 1 nodes in the distributed environment
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:24:09 [distributed/parallel_state.py:1083] Detected 1 nodes in the distributed environment
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:24:09 [distributed/parallel_state.py:1083] Detected 1 nodes in the distributed environment
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:24:09 [distributed/parallel_state.py:1083] Detected 1 nodes in the distributed environment
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:24:09 [distributed/parallel_state.py:1083] Detected 1 nodes in the distributed environment
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:24:09 [distributed/parallel_state.py:1083] Detected 1 nodes in the distributed environment
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:24:09 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:24:09 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:24:09 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:24:09 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:24:09 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:24:09 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:24:09 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:24:09 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:24:09 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:24:09 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:24:09 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:24:09 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:24:09 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:24:09 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:24:09 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:24:09 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:24:10 [v1/engine/utils.py:776] Waiting for 8 local, 0 remote core engine proc(s) to start.
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:24:20 [v1/engine/utils.py:776] Waiting for 8 local, 0 remote core engine proc(s) to start.
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:24:30 [v1/engine/utils.py:776] Waiting for 8 local, 0 remote core engine proc(s) to start.
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:24:40 [v1/engine/utils.py:776] Waiting for 8 local, 0 remote core engine proc(s) to start.
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:24:50 [v1/engine/utils.py:776] Waiting for 8 local, 0 remote core engine proc(s) to start.
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:24:50 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:24:50 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:24:50 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:24:50 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:24:50 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:24:50 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:24:50 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:24:50 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:24:50 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:24:50 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:24:50 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:24:50 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:24:50 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:24:50 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:24:50 [utils/__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:24:50 [distributed/device_communicators/pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:25:00 [v1/engine/utils.py:776] Waiting for 8 local, 0 remote core engine proc(s) to start.
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:25:10 [v1/engine/utils.py:776] Waiting for 8 local, 0 remote core engine proc(s) to start.
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:25:20 [v1/engine/utils.py:776] Waiting for 8 local, 0 remote core engine proc(s) to start.
[1;36m(APIServer pid=1)[0;0m DEBUG 10-17 09:25:30 [v1/engine/utils.py:776] Waiting for 8 local, 0 remote core engine proc(s) to start.
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:25:30 [distributed/device_communicators/cuda_communicator.py:108] Using DeepEP High-Throughput all2all manager.
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:25:30 [distributed/device_communicators/cuda_communicator.py:108] Using DeepEP High-Throughput all2all manager.
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:25:30 [distributed/device_communicators/cuda_communicator.py:108] Using DeepEP High-Throughput all2all manager.
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:25:30 [distributed/device_communicators/cuda_communicator.py:108] Using DeepEP High-Throughput all2all manager.
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:25:30 [distributed/parallel_state.py:1208] rank 0 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:25:30 [distributed/device_communicators/cuda_communicator.py:108] Using DeepEP High-Throughput all2all manager.
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:25:30 [distributed/parallel_state.py:1208] rank 7 in world size 8 is assigned as DP rank 7, PP rank 0, TP rank 0, EP rank 7
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:25:30 [distributed/device_communicators/cuda_communicator.py:108] Using DeepEP High-Throughput all2all manager.
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:25:30 [distributed/parallel_state.py:1208] rank 1 in world size 8 is assigned as DP rank 1, PP rank 0, TP rank 0, EP rank 1
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:25:30 [distributed/parallel_state.py:1208] rank 2 in world size 8 is assigned as DP rank 2, PP rank 0, TP rank 0, EP rank 2
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:25:30 [distributed/device_communicators/cuda_communicator.py:108] Using DeepEP High-Throughput all2all manager.
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:25:30 [distributed/parallel_state.py:1208] rank 6 in world size 8 is assigned as DP rank 6, PP rank 0, TP rank 0, EP rank 6
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:25:30 [distributed/parallel_state.py:1208] rank 3 in world size 8 is assigned as DP rank 3, PP rank 0, TP rank 0, EP rank 3
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:25:30 [distributed/parallel_state.py:1208] rank 5 in world size 8 is assigned as DP rank 5, PP rank 0, TP rank 0, EP rank 5
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:25:30 [distributed/device_communicators/cuda_communicator.py:108] Using DeepEP High-Throughput all2all manager.
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:25:30 [distributed/parallel_state.py:1208] rank 4 in world size 8 is assigned as DP rank 4, PP rank 0, TP rank 0, EP rank 4
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:56] NIXL is available
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:56] NIXL is available
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:56] NIXL is available
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:56] NIXL is available
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:56] NIXL is available
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:25:30 [distributed/.../kv_connector/factory.py:51] Creating v1 connector with name: NixlConnector and engine_id: 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp1
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:25:30 [distributed/.../kv_connector/factory.py:51] Creating v1 connector with name: NixlConnector and engine_id: 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp5
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:465] Initializing NIXL wrapper
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:466] Initializing NIXL worker 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp1
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:465] Initializing NIXL wrapper
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:56] NIXL is available
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:466] Initializing NIXL worker 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp5
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:56] NIXL is available
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:25:30 [distributed/.../kv_connector/factory.py:51] Creating v1 connector with name: NixlConnector and engine_id: 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp2
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:465] Initializing NIXL wrapper
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:466] Initializing NIXL worker 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp2
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:25:30 [distributed/.../kv_connector/factory.py:51] Creating v1 connector with name: NixlConnector and engine_id: 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp3
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:465] Initializing NIXL wrapper
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:25:30 [distributed/.../kv_connector/factory.py:51] Creating v1 connector with name: NixlConnector and engine_id: 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp0
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:466] Initializing NIXL worker 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp3
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:465] Initializing NIXL wrapper
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:466] Initializing NIXL worker 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp0
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:25:30 [distributed/.../kv_connector/factory.py:51] Creating v1 connector with name: NixlConnector and engine_id: 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp6
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:25:30 [distributed/.../kv_connector/factory.py:51] Creating v1 connector with name: NixlConnector and engine_id: 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp7
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:465] Initializing NIXL wrapper
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:466] Initializing NIXL worker 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp6
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:465] Initializing NIXL wrapper
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:466] Initializing NIXL worker 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp7
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:56] NIXL is available
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:25:30 [distributed/.../kv_connector/factory.py:51] Creating v1 connector with name: NixlConnector and engine_id: 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp4
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:465] Initializing NIXL wrapper
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:25:30 [distributed/.../v1/nixl_connector.py:466] Initializing NIXL worker 2e1b5f9d-2d54-450e-ab9d-a7c8f542cc80_dp4
[1;36m(EngineCore_DP4 pid=276)[0;0m 2025-10-17 09:25:30 NIXL INFO    _api.py:354 Backend UCX was instantiated
[1;36m(EngineCore_DP2 pid=274)[0;0m 2025-10-17 09:25:30 NIXL INFO    _api.py:354 Backend UCX was instantiated
[1;36m(EngineCore_DP3 pid=275)[0;0m 2025-10-17 09:25:30 NIXL INFO    _api.py:354 Backend UCX was instantiated
[1;36m(EngineCore_DP0 pid=272)[0;0m 2025-10-17 09:25:30 NIXL INFO    _api.py:354 Backend UCX was instantiated
[1;36m(EngineCore_DP1 pid=273)[0;0m 2025-10-17 09:25:30 NIXL INFO    _api.py:354 Backend UCX was instantiated
[1;36m(EngineCore_DP5 pid=277)[0;0m 2025-10-17 09:25:30 NIXL INFO    _api.py:354 Backend UCX was instantiated
[1;36m(EngineCore_DP7 pid=279)[0;0m 2025-10-17 09:25:30 NIXL INFO    _api.py:354 Backend UCX was instantiated
[1;36m(EngineCore_DP6 pid=278)[0;0m 2025-10-17 09:25:30 NIXL INFO    _api.py:354 Backend UCX was instantiated
[1;36m(EngineCore_DP0 pid=272)[0;0m 2025-10-17 09:25:33 NIXL INFO    _api.py:354 Backend GDS was instantiated
[1;36m(EngineCore_DP0 pid=272)[0;0m 2025-10-17 09:25:33 NIXL INFO    _api.py:244 Initialized NIXL agent: 3d5ae4cb-b7bf-4ec0-aea8-53c9c86abaa8
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:25:33 [platforms/cuda.py:288] Using FlashMLA backend on V1 engine.
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:25:33 [distributed/.../kv_connector/utils.py:114] Connectors do not specify a kv cache layout, defaulting to NHD.
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:25:33 [distributed/.../v1/nixl_connector.py:597] Detected attention backend FLASHMLA
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:25:33 [distributed/.../v1/nixl_connector.py:598] Detected kv cache layout NHD
[1;36m(EngineCore_DP3 pid=275)[0;0m 2025-10-17 09:25:33 NIXL INFO    _api.py:354 Backend GDS was instantiated
[1;36m(EngineCore_DP3 pid=275)[0;0m 2025-10-17 09:25:33 NIXL INFO    _api.py:244 Initialized NIXL agent: 4c64f9a0-fde8-4bdd-a73a-86a66e6244c5
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:25:33 [platforms/cuda.py:288] Using FlashMLA backend on V1 engine.
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:25:34 [distributed/.../kv_connector/utils.py:114] Connectors do not specify a kv cache layout, defaulting to NHD.
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:25:34 [distributed/.../v1/nixl_connector.py:597] Detected attention backend FLASHMLA
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:25:34 [distributed/.../v1/nixl_connector.py:598] Detected kv cache layout NHD
[1;36m(EngineCore_DP2 pid=274)[0;0m 2025-10-17 09:25:34 NIXL INFO    _api.py:354 Backend GDS was instantiated
[1;36m(EngineCore_DP2 pid=274)[0;0m 2025-10-17 09:25:34 NIXL INFO    _api.py:244 Initialized NIXL agent: 23b14f23-70b2-4725-9023-e75f31998046
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:25:34 [platforms/cuda.py:288] Using FlashMLA backend on V1 engine.
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:25:34 [distributed/.../kv_connector/utils.py:114] Connectors do not specify a kv cache layout, defaulting to NHD.
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:25:34 [distributed/.../v1/nixl_connector.py:597] Detected attention backend FLASHMLA
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:25:34 [distributed/.../v1/nixl_connector.py:598] Detected kv cache layout NHD
[1;36m(EngineCore_DP1 pid=273)[0;0m 2025-10-17 09:25:34 NIXL INFO    _api.py:354 Backend GDS was instantiated
[1;36m(EngineCore_DP1 pid=273)[0;0m 2025-10-17 09:25:34 NIXL INFO    _api.py:244 Initialized NIXL agent: cf0cd0b0-c394-4c28-b020-fa97c22b35df
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:25:34 [platforms/cuda.py:288] Using FlashMLA backend on V1 engine.
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:25:34 [distributed/.../kv_connector/utils.py:114] Connectors do not specify a kv cache layout, defaulting to NHD.
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:25:34 [distributed/.../v1/nixl_connector.py:597] Detected attention backend FLASHMLA
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:25:34 [distributed/.../v1/nixl_connector.py:598] Detected kv cache layout NHD
[1;36m(EngineCore_DP4 pid=276)[0;0m 2025-10-17 09:25:34 NIXL INFO    _api.py:354 Backend GDS was instantiated
[1;36m(EngineCore_DP4 pid=276)[0;0m 2025-10-17 09:25:34 NIXL INFO    _api.py:244 Initialized NIXL agent: 48bf1287-fc84-424a-b220-729a143d207a
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:25:34 [platforms/cuda.py:288] Using FlashMLA backend on V1 engine.
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:25:34 [distributed/.../kv_connector/utils.py:114] Connectors do not specify a kv cache layout, defaulting to NHD.
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:25:34 [distributed/.../v1/nixl_connector.py:597] Detected attention backend FLASHMLA
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:25:34 [distributed/.../v1/nixl_connector.py:598] Detected kv cache layout NHD
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:25:34 [v1/sample/ops/topk_topp_sampler.py:55] Using FlashInfer for top-p & top-k sampling.
[1;36m(EngineCore_DP7 pid=279)[0;0m 2025-10-17 09:25:34 NIXL INFO    _api.py:354 Backend GDS was instantiated
[1;36m(EngineCore_DP7 pid=279)[0;0m 2025-10-17 09:25:34 NIXL INFO    _api.py:244 Initialized NIXL agent: 983ab11a-469f-49ce-b1de-ae5411250ba4
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:25:34 [v1/sample/logits_processor/__init__.py:57] No logitsprocs plugins installed (group vllm.logits_processors).
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:25:34 [platforms/cuda.py:288] Using FlashMLA backend on V1 engine.
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:25:34 [distributed/.../kv_connector/utils.py:114] Connectors do not specify a kv cache layout, defaulting to NHD.
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:25:34 [distributed/.../v1/nixl_connector.py:597] Detected attention backend FLASHMLA
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:25:34 [distributed/.../v1/nixl_connector.py:598] Detected kv cache layout NHD
[1;36m(EngineCore_DP5 pid=277)[0;0m 2025-10-17 09:25:34 NIXL INFO    _api.py:354 Backend GDS was instantiated
[1;36m(EngineCore_DP5 pid=277)[0;0m 2025-10-17 09:25:34 NIXL INFO    _api.py:244 Initialized NIXL agent: f8e27f64-41ba-4d4d-a624-38d21460ebd7
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:25:34 [platforms/cuda.py:288] Using FlashMLA backend on V1 engine.
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:25:34 [distributed/.../kv_connector/utils.py:114] Connectors do not specify a kv cache layout, defaulting to NHD.
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:25:34 [distributed/.../v1/nixl_connector.py:597] Detected attention backend FLASHMLA
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:25:34 [distributed/.../v1/nixl_connector.py:598] Detected kv cache layout NHD
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:25:34 [v1/worker/gpu_model_runner.py:2602] Starting to load model deepseek-ai/DeepSeek-V3-0324...
[1;36m(EngineCore_DP6 pid=278)[0;0m 2025-10-17 09:25:34 NIXL INFO    _api.py:354 Backend GDS was instantiated
[1;36m(EngineCore_DP6 pid=278)[0;0m 2025-10-17 09:25:34 NIXL INFO    _api.py:244 Initialized NIXL agent: 95664c92-2f17-43fd-a6a8-62ec283170ff
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:25:34 [platforms/cuda.py:288] Using FlashMLA backend on V1 engine.
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:25:34 [distributed/.../kv_connector/utils.py:114] Connectors do not specify a kv cache layout, defaulting to NHD.
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:25:34 [distributed/.../v1/nixl_connector.py:597] Detected attention backend FLASHMLA
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:25:34 [distributed/.../v1/nixl_connector.py:598] Detected kv cache layout NHD
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:25:34 [v1/sample/ops/topk_topp_sampler.py:55] Using FlashInfer for top-p & top-k sampling.
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:25:34 [v1/sample/ops/topk_topp_sampler.py:55] Using FlashInfer for top-p & top-k sampling.
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:25:34 [v1/sample/ops/topk_topp_sampler.py:55] Using FlashInfer for top-p & top-k sampling.
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:25:34 [v1/sample/logits_processor/__init__.py:57] No logitsprocs plugins installed (group vllm.logits_processors).
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:25:34 [v1/sample/logits_processor/__init__.py:57] No logitsprocs plugins installed (group vllm.logits_processors).
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:25:34 [v1/sample/logits_processor/__init__.py:57] No logitsprocs plugins installed (group vllm.logits_processors).
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:25:34 [v1/sample/ops/topk_topp_sampler.py:55] Using FlashInfer for top-p & top-k sampling.
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:25:34 [v1/sample/logits_processor/__init__.py:57] No logitsprocs plugins installed (group vllm.logits_processors).
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:25:34 [v1/worker/gpu_model_runner.py:2602] Starting to load model deepseek-ai/DeepSeek-V3-0324...
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:25:34 [v1/worker/gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:25:34 [v1/sample/ops/topk_topp_sampler.py:55] Using FlashInfer for top-p & top-k sampling.
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:25:34 [v1/worker/gpu_model_runner.py:2602] Starting to load model deepseek-ai/DeepSeek-V3-0324...
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:25:34 [v1/sample/ops/topk_topp_sampler.py:55] Using FlashInfer for top-p & top-k sampling.
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:25:34 [v1/sample/ops/topk_topp_sampler.py:55] Using FlashInfer for top-p & top-k sampling.
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:25:34 [v1/worker/gpu_model_runner.py:2602] Starting to load model deepseek-ai/DeepSeek-V3-0324...
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:25:34 [v1/sample/logits_processor/__init__.py:57] No logitsprocs plugins installed (group vllm.logits_processors).
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:25:34 [v1/sample/logits_processor/__init__.py:57] No logitsprocs plugins installed (group vllm.logits_processors).
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:25:34 [v1/sample/logits_processor/__init__.py:57] No logitsprocs plugins installed (group vllm.logits_processors).
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:25:35 [v1/attention/.../mla/common.py:1128] Using FlashAttention prefill for MLA
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:25:35 [v1/worker/gpu_model_runner.py:2602] Starting to load model deepseek-ai/DeepSeek-V3-0324...
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:25:35 [model_executor/.../fused_moe/layer.py:1052] [EP Rank 0/8] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 32/256. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7, 8->8, 9->9, 10->10, 11->11, 12->12, 13->13, 14->14, 15->15, 16->16, 17->17, 18->18, 19->19, 20->20, 21->21, 22->22, 23->23, 24->24, 25->25, 26->26, 27->27, 28->28, 29->29, 30->30, 31->31.
[1;36m(EngineCore_DP0 pid=272)[0;0m DEBUG 10-17 09:25:35 [model_executor/.../fused_moe/config.py:752] Using FusedMoEConfig::max_num_tokens=512
[1;36m(EngineCore_DP0 pid=272)[0;0m INFO 10-17 09:25:35 [model_executor/.../quantization/fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP0 pid=272)[0;0m WARNING 10-17 09:25:35 [model_executor/.../quantization/fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:25:35 [v1/worker/gpu_model_runner.py:2602] Starting to load model deepseek-ai/DeepSeek-V3-0324...
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:25:35 [v1/worker/gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:25:35 [v1/worker/gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:25:35 [v1/worker/gpu_model_runner.py:2602] Starting to load model deepseek-ai/DeepSeek-V3-0324...
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:25:35 [v1/worker/gpu_model_runner.py:2602] Starting to load model deepseek-ai/DeepSeek-V3-0324...
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:25:35 [v1/worker/gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:25:35 [v1/worker/gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:25:35 [v1/attention/.../mla/common.py:1128] Using FlashAttention prefill for MLA
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:25:35 [v1/attention/.../mla/common.py:1128] Using FlashAttention prefill for MLA
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:25:35 [v1/attention/.../mla/common.py:1128] Using FlashAttention prefill for MLA
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:25:35 [model_executor/.../fused_moe/layer.py:1052] [EP Rank 2/8] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 32/256. Experts local to global index map: 0->64, 1->65, 2->66, 3->67, 4->68, 5->69, 6->70, 7->71, 8->72, 9->73, 10->74, 11->75, 12->76, 13->77, 14->78, 15->79, 16->80, 17->81, 18->82, 19->83, 20->84, 21->85, 22->86, 23->87, 24->88, 25->89, 26->90, 27->91, 28->92, 29->93, 30->94, 31->95.
[1;36m(EngineCore_DP2 pid=274)[0;0m DEBUG 10-17 09:25:35 [model_executor/.../fused_moe/config.py:752] Using FusedMoEConfig::max_num_tokens=512
[1;36m(EngineCore_DP2 pid=274)[0;0m INFO 10-17 09:25:35 [model_executor/.../quantization/fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP2 pid=274)[0;0m WARNING 10-17 09:25:35 [model_executor/.../quantization/fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:25:35 [v1/attention/.../mla/common.py:1128] Using FlashAttention prefill for MLA
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:25:35 [model_executor/.../fused_moe/layer.py:1052] [EP Rank 1/8] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 32/256. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39, 8->40, 9->41, 10->42, 11->43, 12->44, 13->45, 14->46, 15->47, 16->48, 17->49, 18->50, 19->51, 20->52, 21->53, 22->54, 23->55, 24->56, 25->57, 26->58, 27->59, 28->60, 29->61, 30->62, 31->63.
[1;36m(EngineCore_DP1 pid=273)[0;0m DEBUG 10-17 09:25:35 [model_executor/.../fused_moe/config.py:752] Using FusedMoEConfig::max_num_tokens=512
[1;36m(EngineCore_DP1 pid=273)[0;0m INFO 10-17 09:25:35 [model_executor/.../quantization/fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP1 pid=273)[0;0m WARNING 10-17 09:25:35 [model_executor/.../quantization/fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:25:35 [v1/worker/gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:25:35 [model_executor/.../fused_moe/layer.py:1052] [EP Rank 3/8] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 32/256. Experts local to global index map: 0->96, 1->97, 2->98, 3->99, 4->100, 5->101, 6->102, 7->103, 8->104, 9->105, 10->106, 11->107, 12->108, 13->109, 14->110, 15->111, 16->112, 17->113, 18->114, 19->115, 20->116, 21->117, 22->118, 23->119, 24->120, 25->121, 26->122, 27->123, 28->124, 29->125, 30->126, 31->127.
[1;36m(EngineCore_DP3 pid=275)[0;0m DEBUG 10-17 09:25:35 [model_executor/.../fused_moe/config.py:752] Using FusedMoEConfig::max_num_tokens=512
[1;36m(EngineCore_DP3 pid=275)[0;0m INFO 10-17 09:25:35 [model_executor/.../quantization/fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP3 pid=275)[0;0m WARNING 10-17 09:25:35 [model_executor/.../quantization/fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:25:35 [model_executor/.../fused_moe/layer.py:1052] [EP Rank 7/8] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 32/256. Experts local to global index map: 0->224, 1->225, 2->226, 3->227, 4->228, 5->229, 6->230, 7->231, 8->232, 9->233, 10->234, 11->235, 12->236, 13->237, 14->238, 15->239, 16->240, 17->241, 18->242, 19->243, 20->244, 21->245, 22->246, 23->247, 24->248, 25->249, 26->250, 27->251, 28->252, 29->253, 30->254, 31->255.
[1;36m(EngineCore_DP7 pid=279)[0;0m DEBUG 10-17 09:25:35 [model_executor/.../fused_moe/config.py:752] Using FusedMoEConfig::max_num_tokens=512
[1;36m(EngineCore_DP7 pid=279)[0;0m INFO 10-17 09:25:35 [model_executor/.../quantization/fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP7 pid=279)[0;0m WARNING 10-17 09:25:35 [model_executor/.../quantization/fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:25:35 [v1/worker/gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:25:35 [v1/worker/gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:25:35 [v1/attention/.../mla/common.py:1128] Using FlashAttention prefill for MLA
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:25:35 [model_executor/.../fused_moe/layer.py:1052] [EP Rank 6/8] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 32/256. Experts local to global index map: 0->192, 1->193, 2->194, 3->195, 4->196, 5->197, 6->198, 7->199, 8->200, 9->201, 10->202, 11->203, 12->204, 13->205, 14->206, 15->207, 16->208, 17->209, 18->210, 19->211, 20->212, 21->213, 22->214, 23->215, 24->216, 25->217, 26->218, 27->219, 28->220, 29->221, 30->222, 31->223.
[1;36m(EngineCore_DP6 pid=278)[0;0m DEBUG 10-17 09:25:35 [model_executor/.../fused_moe/config.py:752] Using FusedMoEConfig::max_num_tokens=512
[1;36m(EngineCore_DP6 pid=278)[0;0m INFO 10-17 09:25:35 [model_executor/.../quantization/fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP6 pid=278)[0;0m WARNING 10-17 09:25:35 [model_executor/.../quantization/fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:25:35 [v1/attention/.../mla/common.py:1128] Using FlashAttention prefill for MLA
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:25:35 [v1/attention/.../mla/common.py:1128] Using FlashAttention prefill for MLA
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:25:35 [model_executor/.../fused_moe/layer.py:1052] [EP Rank 5/8] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 32/256. Experts local to global index map: 0->160, 1->161, 2->162, 3->163, 4->164, 5->165, 6->166, 7->167, 8->168, 9->169, 10->170, 11->171, 12->172, 13->173, 14->174, 15->175, 16->176, 17->177, 18->178, 19->179, 20->180, 21->181, 22->182, 23->183, 24->184, 25->185, 26->186, 27->187, 28->188, 29->189, 30->190, 31->191.
[1;36m(EngineCore_DP5 pid=277)[0;0m DEBUG 10-17 09:25:35 [model_executor/.../fused_moe/config.py:752] Using FusedMoEConfig::max_num_tokens=512
[1;36m(EngineCore_DP5 pid=277)[0;0m INFO 10-17 09:25:35 [model_executor/.../quantization/fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP5 pid=277)[0;0m WARNING 10-17 09:25:35 [model_executor/.../quantization/fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:25:35 [model_executor/.../fused_moe/layer.py:1052] [EP Rank 4/8] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 32/256. Experts local to global index map: 0->128, 1->129, 2->130, 3->131, 4->132, 5->133, 6->134, 7->135, 8->136, 9->137, 10->138, 11->139, 12->140, 13->141, 14->142, 15->143, 16->144, 17->145, 18->146, 19->147, 20->148, 21->149, 22->150, 23->151, 24->152, 25->153, 26->154, 27->155, 28->156, 29->157, 30->158, 31->159.
[1;36m(EngineCore_DP4 pid=276)[0;0m DEBUG 10-17 09:25:35 [model_executor/.../fused_moe/config.py:752] Using FusedMoEConfig::max_num_tokens=512
[1;36m(EngineCore_DP4 pid=276)[0;0m INFO 10-17 09:25:35 [model_executor/.../quantization/fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP4 pid=276)[0;0m WARNING 10-17 09:25:35 [model_executor/.../quantization/fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self._init_executor()
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.collective_rpc("load_model")
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(**kwargs)
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=272)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=272)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=272)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 712, in run_engine_core
[1;36m(EngineCore_DP0 pid=272)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP0 pid=272)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=272)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=272)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP0 pid=272)[0;0m     self.collective_rpc("load_model")
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP0 pid=272)[0;0m     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP0 pid=272)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP0 pid=272)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=272)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP0 pid=272)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP0 pid=272)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=272)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP0 pid=272)[0;0m     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP0 pid=272)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP0 pid=272)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=272)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP0 pid=272)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=272)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP0 pid=272)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=272)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP0 pid=272)[0;0m     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP0 pid=272)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP0 pid=272)[0;0m                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP0 pid=272)[0;0m                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m     super().__init__(**kwargs)
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP0 pid=272)[0;0m     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP0 pid=272)[0;0m     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP0 pid=272)[0;0m                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=272)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=272)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=272)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP2 pid=274)[0;0m Process EngineCore_DP2:
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] EngineCore failed to start.
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] Traceback (most recent call last):
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self._init_executor()
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.collective_rpc("load_model")
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(**kwargs)
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP2 pid=274)[0;0m     self.run()
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP2 pid=274)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 712, in run_engine_core
[1;36m(EngineCore_DP2 pid=274)[0;0m     raise e
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP2 pid=274)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP2 pid=274)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP2 pid=274)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m     self._init_executor()
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP2 pid=274)[0;0m     self.collective_rpc("load_model")
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP2 pid=274)[0;0m     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP2 pid=274)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP2 pid=274)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP2 pid=274)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP2 pid=274)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP2 pid=274)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP2 pid=274)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP2 pid=274)[0;0m     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP2 pid=274)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP2 pid=274)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP2 pid=274)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP2 pid=274)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP2 pid=274)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP2 pid=274)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP2 pid=274)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP2 pid=274)[0;0m     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP2 pid=274)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP2 pid=274)[0;0m                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP2 pid=274)[0;0m                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m     super().__init__(**kwargs)
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP2 pid=274)[0;0m     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP2 pid=274)[0;0m     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP2 pid=274)[0;0m                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP2 pid=274)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP2 pid=274)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP2 pid=274)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP3 pid=275)[0;0m Process EngineCore_DP3:
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] EngineCore failed to start.
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] Traceback (most recent call last):
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self._init_executor()
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.collective_rpc("load_model")
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(**kwargs)
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP3 pid=275)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP3 pid=275)[0;0m     self.run()
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP3 pid=275)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 712, in run_engine_core
[1;36m(EngineCore_DP3 pid=275)[0;0m     raise e
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP3 pid=275)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP3 pid=275)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP3 pid=275)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m     self._init_executor()
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP3 pid=275)[0;0m     self.collective_rpc("load_model")
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP3 pid=275)[0;0m     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP3 pid=275)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP3 pid=275)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP3 pid=275)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP3 pid=275)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP3 pid=275)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP3 pid=275)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP3 pid=275)[0;0m     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP3 pid=275)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP3 pid=275)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP3 pid=275)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP3 pid=275)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP3 pid=275)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP3 pid=275)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP3 pid=275)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP3 pid=275)[0;0m     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP3 pid=275)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP3 pid=275)[0;0m                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP3 pid=275)[0;0m                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m     super().__init__(**kwargs)
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP3 pid=275)[0;0m     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP3 pid=275)[0;0m     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP3 pid=275)[0;0m                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP3 pid=275)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP3 pid=275)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP3 pid=275)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP7 pid=279)[0;0m Process EngineCore_DP7:
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] EngineCore failed to start.
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] Traceback (most recent call last):
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self._init_executor()
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.collective_rpc("load_model")
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(**kwargs)
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP7 pid=279)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP7 pid=279)[0;0m     self.run()
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP7 pid=279)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 712, in run_engine_core
[1;36m(EngineCore_DP7 pid=279)[0;0m     raise e
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP7 pid=279)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP7 pid=279)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP7 pid=279)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m     self._init_executor()
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP7 pid=279)[0;0m     self.collective_rpc("load_model")
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP7 pid=279)[0;0m     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP7 pid=279)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP7 pid=279)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP7 pid=279)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP7 pid=279)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP7 pid=279)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP7 pid=279)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP7 pid=279)[0;0m     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP7 pid=279)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP7 pid=279)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP7 pid=279)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP7 pid=279)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP7 pid=279)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP7 pid=279)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP7 pid=279)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP7 pid=279)[0;0m     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP7 pid=279)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP7 pid=279)[0;0m                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP7 pid=279)[0;0m                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m     super().__init__(**kwargs)
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP7 pid=279)[0;0m     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP7 pid=279)[0;0m     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP7 pid=279)[0;0m                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP7 pid=279)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP7 pid=279)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP7 pid=279)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] EngineCore failed to start.
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] Traceback (most recent call last):
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self._init_executor()
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.collective_rpc("load_model")
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP6 pid=278)[0;0m Process EngineCore_DP6:
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(**kwargs)
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP6 pid=278)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP6 pid=278)[0;0m     self.run()
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP6 pid=278)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 712, in run_engine_core
[1;36m(EngineCore_DP6 pid=278)[0;0m     raise e
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP6 pid=278)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP6 pid=278)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP6 pid=278)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m     self._init_executor()
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP6 pid=278)[0;0m     self.collective_rpc("load_model")
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP6 pid=278)[0;0m     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP6 pid=278)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP6 pid=278)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP6 pid=278)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP6 pid=278)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP6 pid=278)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP6 pid=278)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP6 pid=278)[0;0m     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP6 pid=278)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP6 pid=278)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP6 pid=278)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP6 pid=278)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP6 pid=278)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP6 pid=278)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP6 pid=278)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP6 pid=278)[0;0m     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP6 pid=278)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP6 pid=278)[0;0m                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP6 pid=278)[0;0m                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m     super().__init__(**kwargs)
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP6 pid=278)[0;0m     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP6 pid=278)[0;0m     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP6 pid=278)[0;0m                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP6 pid=278)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP6 pid=278)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP6 pid=278)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] EngineCore failed to start.
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] Traceback (most recent call last):
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP1 pid=273)[0;0m Process EngineCore_DP1:
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self._init_executor()
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.collective_rpc("load_model")
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(**kwargs)
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP1 pid=273)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP1 pid=273)[0;0m     self.run()
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP1 pid=273)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 712, in run_engine_core
[1;36m(EngineCore_DP1 pid=273)[0;0m     raise e
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP1 pid=273)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP1 pid=273)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP1 pid=273)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m     self._init_executor()
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP1 pid=273)[0;0m     self.collective_rpc("load_model")
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP1 pid=273)[0;0m     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP1 pid=273)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP1 pid=273)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP1 pid=273)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP1 pid=273)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP1 pid=273)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP1 pid=273)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP1 pid=273)[0;0m     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP1 pid=273)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP1 pid=273)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP1 pid=273)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP1 pid=273)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP1 pid=273)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP1 pid=273)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP1 pid=273)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP1 pid=273)[0;0m     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP1 pid=273)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP1 pid=273)[0;0m                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP1 pid=273)[0;0m                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m     super().__init__(**kwargs)
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP1 pid=273)[0;0m     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP1 pid=273)[0;0m     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP1 pid=273)[0;0m                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP1 pid=273)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP1 pid=273)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP1 pid=273)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP5 pid=277)[0;0m Process EngineCore_DP5:
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] EngineCore failed to start.
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] Traceback (most recent call last):
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self._init_executor()
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.collective_rpc("load_model")
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(**kwargs)
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP5 pid=277)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP5 pid=277)[0;0m     self.run()
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP5 pid=277)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 712, in run_engine_core
[1;36m(EngineCore_DP5 pid=277)[0;0m     raise e
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP5 pid=277)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP5 pid=277)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP5 pid=277)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m     self._init_executor()
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP5 pid=277)[0;0m     self.collective_rpc("load_model")
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP5 pid=277)[0;0m     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP5 pid=277)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP5 pid=277)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP5 pid=277)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP5 pid=277)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP5 pid=277)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP5 pid=277)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP5 pid=277)[0;0m     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP5 pid=277)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP5 pid=277)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP5 pid=277)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP5 pid=277)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP5 pid=277)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP5 pid=277)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP5 pid=277)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP5 pid=277)[0;0m     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP5 pid=277)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP5 pid=277)[0;0m                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP5 pid=277)[0;0m                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m     super().__init__(**kwargs)
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP5 pid=277)[0;0m     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP5 pid=277)[0;0m     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP5 pid=277)[0;0m                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP5 pid=277)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP5 pid=277)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP5 pid=277)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1017 09:25:36.342847883 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] EngineCore failed to start.
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] Traceback (most recent call last):
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self._init_executor()
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.collective_rpc("load_model")
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP4 pid=276)[0;0m Process EngineCore_DP4:
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     super().__init__(**kwargs)
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m ERROR 10-17 09:25:36 [v1/engine/core.py:708] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP4 pid=276)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP4 pid=276)[0;0m     self.run()
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP4 pid=276)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 712, in run_engine_core
[1;36m(EngineCore_DP4 pid=276)[0;0m     raise e
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 695, in run_engine_core
[1;36m(EngineCore_DP4 pid=276)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP4 pid=276)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 965, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m     super().__init__(vllm_config, local_client, handshake_address,
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP4 pid=276)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m     self._init_executor()
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 55, in _init_executor
[1;36m(EngineCore_DP4 pid=276)[0;0m     self.collective_rpc("load_model")
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP4 pid=276)[0;0m     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP4 pid=276)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP4 pid=276)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP4 pid=276)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 213, in load_model
[1;36m(EngineCore_DP4 pid=276)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2635, in load_model
[1;36m(EngineCore_DP4 pid=276)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP4 pid=276)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 45, in load_model
[1;36m(EngineCore_DP4 pid=276)[0;0m     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_DP4 pid=276)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_DP4 pid=276)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP4 pid=276)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1208, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m     self.model = DeepseekV2Model(vllm_config=vllm_config,
[1;36m(EngineCore_DP4 pid=276)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/compilation/decorators.py", line 201, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1135, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP4 pid=276)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/utils.py", line 630, in make_layers
[1;36m(EngineCore_DP4 pid=276)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP4 pid=276)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1137, in <lambda>
[1;36m(EngineCore_DP4 pid=276)[0;0m     lambda prefix: DeepseekV2DecoderLayer(vllm_config, prefix,
[1;36m(EngineCore_DP4 pid=276)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 1037, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m     self.mlp = DeepseekV2MoE(
[1;36m(EngineCore_DP4 pid=276)[0;0m                ^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/deepseek_v2.py", line 220, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m     self.experts = SharedFusedMoE(
[1;36m(EngineCore_DP4 pid=276)[0;0m                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py", line 25, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m     super().__init__(**kwargs)
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/fused_moe/layer.py", line 1140, in __init__
[1;36m(EngineCore_DP4 pid=276)[0;0m     self.quant_method.create_weights(layer=self, **moe_quant_params)
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/model_executor/layers/quantization/fp8.py", line 531, in create_weights
[1;36m(EngineCore_DP4 pid=276)[0;0m     w2_weight = torch.nn.Parameter(torch.empty(
[1;36m(EngineCore_DP4 pid=276)[0;0m                                    ^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP4 pid=276)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP4 pid=276)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP4 pid=276)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.19 GiB of which 437.06 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 76.58 GiB is allocated by PyTorch, and 192.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank2]:[W1017 09:25:37.555125329 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank3]:[W1017 09:25:37.599055264 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank7]:[W1017 09:25:37.631370941 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank6]:[W1017 09:25:37.675231532 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank1]:[W1017 09:25:37.876613533 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank5]:[W1017 09:25:37.923616834 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank4]:[W1017 09:25:37.138359109 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[1;36m(APIServer pid=1)[0;0m Traceback (most recent call last):
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/bin/vllm", line 10, in <module>
[1;36m(APIServer pid=1)[0;0m     sys.exit(main())
[1;36m(APIServer pid=1)[0;0m              ^^^^^^
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/entrypoints/cli/main.py", line 54, in main
[1;36m(APIServer pid=1)[0;0m     args.dispatch_function(args)
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/entrypoints/cli/serve.py", line 57, in cmd
[1;36m(APIServer pid=1)[0;0m     uvloop.run(run_server(args))
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/uvloop/__init__.py", line 109, in run
[1;36m(APIServer pid=1)[0;0m     return __asyncio.run(
[1;36m(APIServer pid=1)[0;0m            ^^^^^^^^^^^^^^
[1;36m(APIServer pid=1)[0;0m   File "/usr/lib/python3.12/asyncio/runners.py", line 195, in run
[1;36m(APIServer pid=1)[0;0m     return runner.run(main)
[1;36m(APIServer pid=1)[0;0m            ^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1)[0;0m   File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
[1;36m(APIServer pid=1)[0;0m     return self._loop.run_until_complete(task)
[1;36m(APIServer pid=1)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1)[0;0m   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/uvloop/__init__.py", line 61, in wrapper
[1;36m(APIServer pid=1)[0;0m     return await main
[1;36m(APIServer pid=1)[0;0m            ^^^^^^^^^^
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/entrypoints/openai/api_server.py", line 1884, in run_server
[1;36m(APIServer pid=1)[0;0m     await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/entrypoints/openai/api_server.py", line 1902, in run_server_worker
[1;36m(APIServer pid=1)[0;0m     async with build_async_engine_client(
[1;36m(APIServer pid=1)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1)[0;0m   File "/usr/lib/python3.12/contextlib.py", line 210, in __aenter__
[1;36m(APIServer pid=1)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=1)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/entrypoints/openai/api_server.py", line 180, in build_async_engine_client
[1;36m(APIServer pid=1)[0;0m     async with build_async_engine_client_from_engine_args(
[1;36m(APIServer pid=1)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1)[0;0m   File "/usr/lib/python3.12/contextlib.py", line 210, in __aenter__
[1;36m(APIServer pid=1)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=1)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/entrypoints/openai/api_server.py", line 225, in build_async_engine_client_from_engine_args
[1;36m(APIServer pid=1)[0;0m     async_llm = AsyncLLM.from_vllm_config(
[1;36m(APIServer pid=1)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/utils/__init__.py", line 1572, in inner
[1;36m(APIServer pid=1)[0;0m     return fn(*args, **kwargs)
[1;36m(APIServer pid=1)[0;0m            ^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/async_llm.py", line 207, in from_vllm_config
[1;36m(APIServer pid=1)[0;0m     return cls(
[1;36m(APIServer pid=1)[0;0m            ^^^^
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/async_llm.py", line 134, in __init__
[1;36m(APIServer pid=1)[0;0m     self.engine_core = EngineCoreClient.make_async_mp_client(
[1;36m(APIServer pid=1)[0;0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core_client.py", line 101, in make_async_mp_client
[1;36m(APIServer pid=1)[0;0m     return DPLBAsyncMPClient(*client_args)
[1;36m(APIServer pid=1)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core_client.py", line 1125, in __init__
[1;36m(APIServer pid=1)[0;0m     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core_client.py", line 975, in __init__
[1;36m(APIServer pid=1)[0;0m     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core_client.py", line 769, in __init__
[1;36m(APIServer pid=1)[0;0m     super().__init__(
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core_client.py", line 448, in __init__
[1;36m(APIServer pid=1)[0;0m     with launch_core_engines(vllm_config, executor_class,
[1;36m(APIServer pid=1)[0;0m          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1)[0;0m   File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
[1;36m(APIServer pid=1)[0;0m     next(self.gen)
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/utils.py", line 732, in launch_core_engines
[1;36m(APIServer pid=1)[0;0m     wait_for_engine_startup(
[1;36m(APIServer pid=1)[0;0m   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/utils.py", line 785, in wait_for_engine_startup
[1;36m(APIServer pid=1)[0;0m     raise RuntimeError("Engine core initialization failed. "
[1;36m(APIServer pid=1)[0;0m RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
